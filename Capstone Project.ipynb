{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "For this project I pick 2 different main datasets to make analysis which datasets are I94 US Immigration and US city demopgraphic data. I prefer to use python pandas and Apache Spark for data wrangling and data cleansing operations and serving final product of data tables are parquet files  analysis data for data science and analysis teams.\n",
    "\n",
    "\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "In this project we are creating analysis data for answering set of questions that help our company to increase profit and productivity to further.<br>\n",
    "\n",
    "Here our questions that we need to get really detailed answers for our analysis ;<br>\n",
    "What is the reason of coming usa studying , touristic or business ? <br>\n",
    "What is the population of state that they arrive ?<br>\n",
    "Which countries people are coming from to Usa ?<br>\n",
    "What are the age average of the students, tourists or business people ? <br>\n",
    "What are the top 3 states that tourists visit ?<br>\n",
    "\n",
    "\n",
    "#### Describe and Gather Data \n",
    "We are going to use 2 different data sources and addition \"I94_SAS_Labels_Descriptions.SAS\" for this project.\n",
    "\n",
    "I94 Immigration Data: <br>\n",
    "Data contains of really cool details about  international visitor arrival statistics by world regions. We can answer plenty of questions to make analysis after we complete our work. This data comes from the US National Tourism and Trade Office and this is going to be our core data and we are planning to create our fact table from this immigration dataset then at the end we will going to place our dimension tables around it. You can reach dataset from https://www.trade.gov/national-travel-and-tourism-office\n",
    "\n",
    "U.S. City Demographic Data: <br>\n",
    "This data comes from OpenSoft. You can reach dataset from https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/\n",
    "\n",
    "I94_SAS_Labels_Descriptions.SAS:<br>\n",
    "This file is like dictionary file and I will use this file as my some of  dim table data source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utility_functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col , monotonically_increasing_id\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType , DateType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Setting up our spark session and create\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\",\"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\",\"com.amazonaws:aws-java-sdk:1.7.4,saurfang:spark-sas7bdat:2.0.0-s_2.11,org.apache.hadoop:hadoop-aws:2.7.2\").\\\n",
    "config(\"spark.hadoop.fs.s3a.path.style.access\", True). \\\n",
    "config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\"). \\\n",
    "config(\"com.amazonaws.services.s3.enableV4\", True). \\\n",
    "config(\"spark.driver.extraJavaOptions\", \"-Dcom.amazonaws.services.s3.enableV4=true\"). \\\n",
    "enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Defining path of files that we are going to use inside data exploration functions below\n",
    "path_i94='../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "path_demo=\"./other_datasets/us-cities-demographics.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Immigration Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def i94_data_exp(fn_94_part):\n",
    "    \"\"\"\n",
    "    this function accepts f_94_part as file path and return spark datafram\n",
    "    \"\"\"\n",
    "    #just to see whats inside this dataset I read 1 month.\n",
    "    df_i94 = spark.read.format('com.github.saurfang.sas.spark').load(fn_94_part)\n",
    "    return df_i94\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_i94=i94_data_exp(path_i94)\n",
    "df_i94.limit(3).toPandas()\n",
    "df_i94.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### i94 Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Column | Description \n",
    "-----|-----\n",
    "cicid|Unique record ID\n",
    "i94yr|4 digit year\n",
    "i94mon|Numeric month\n",
    "i94cit|3 digit code for immigrant country of birth\n",
    "i94res|3 digit code for immigrant country of residence\n",
    "i94port|Port\n",
    "arrdate|Arrival Date in the USA\n",
    "i94mode|Mode of transportation (1 = Air; 2 = Sea; 3 = Land; 9 = Not reported)\n",
    "i94addr|State of arrival\n",
    "depdate|Departure Date\n",
    "i94bir|Age\n",
    "i94visa|Visa codes (1 = Business, 2 = Pleasure, 3 = Student)\n",
    "count|Used for summary statistics\n",
    "dtadfile|Character Date Field\n",
    "visapost|Department of State where where Visa was issued\n",
    "occup|Occupation that will be performed in U.S\n",
    "entdepa|Arrival Flag - admitted or paroled into the U.S.\n",
    "entdepd|Departure Flag - Departed, lost I-94 or is deceased\n",
    "entdepu|Update Flag - Either apprehended, overstayed, adjusted to perm residence\n",
    "matflag|Match flag - Match of arrival and departure records\n",
    "biryear|4 digit year of birth\n",
    "dtaddto|Character Date Field - Date to which admitted to U.S. (allowed to stay until)\n",
    "gender|Non-immigrant sex\n",
    "insnum|INS number\n",
    "airline|Airline used to arrive in U.S.\n",
    "admnum|Admission Number\n",
    "fltno|Flight number of Airline used to arrive in U.S.\n",
    "visatype|Class of admission legally admitting the non-immigrant to temporarily stay in U.S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Demographics Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loading demographics dataset to our dataset\n",
    "fn_demo = \"./other_datasets/us-cities-demographics.csv\"\n",
    "df_demo = spark.read.csv(fn_demo, inferSchema=True, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring       Maryland        33.8            40601   \n",
       "1         Quincy  Massachusetts        41.0            44129   \n",
       "2         Hoover        Alabama        38.5            38040   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "\n",
       "   Average Household Size State Code                Race  Count  \n",
       "0                    2.60         MD  Hispanic or Latino  25924  \n",
       "1                    2.39         MA               White  58723  \n",
       "2                    2.58         AL               Asian   4759  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking 3 rows of demo data\n",
    "df_demo.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing schema for better view of dataset\n",
    "df_demo.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    " ### Demographics Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Column | Description \n",
    "-----|-----\n",
    "City|City Name\n",
    "State|US State where city is located\n",
    "Median Age|Median age of the population\n",
    "Male Population|Count of male population\n",
    "Female Population|Count of female population\n",
    "Total Population|Count of total population\n",
    "Number of Veterans|Count of total Veterans\n",
    "Foreign born|Count of residents of the city that were not born in the city\n",
    "Average Household Size|Average city household size\n",
    "State Code|Code of the US state\n",
    "Race|Race\n",
    "Count|Count of city ,  per race\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Extracting Country from Description File - SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_country():\n",
    "    \"\"\"\n",
    "    This function has no parameter \n",
    "    extracts countries from sas file and return \n",
    "    \"\"\"\n",
    "    df_country = extract_content(\"i94cntyl\")\n",
    "    df_country.loc[len(df_country.index)] = ['99', 'All Other Codes']\n",
    "    df_country['code'] = df_country['code'].astype('int32')\n",
    "    return df_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                                         definition\n",
       "0   582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1   236                                        AFGHANISTAN\n",
       "2   101                                            ALBANIA\n",
       "3   316                                            ALGERIA\n",
       "4   102                                            ANDORRA"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country = extract_country()\n",
    "df_country.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Extracting States from Description File - SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_state():\n",
    "    \"\"\"\n",
    "    This function has no parameter \n",
    "    extracts states from sas file and return \n",
    "     \"\"\"\n",
    "    df_state = extract_content(\"i94addrl\")\n",
    "    df_state.insert(0,'id',range(1,1+len(df_state)))\n",
    "    return df_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id code  definition\n",
       "0   1   AL     ALABAMA\n",
       "1   2   AK      ALASKA\n",
       "2   3   AZ     ARIZONA\n",
       "3   4   AR    ARKANSAS\n",
       "4   5   CA  CALIFORNIA"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state = extract_state()\n",
    "df_state.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Extracting Modes from Description File - SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_mode():\n",
    "    \"\"\"\n",
    "    This function has no parameter \n",
    "    extracts mode from sas file and return \n",
    "     \"\"\"\n",
    "    df_mode = extract_content(\"i94mode\")\n",
    "    df_mode.loc[len(df_mode.index)] = ['-99', 'No Mode Value']\n",
    "    df_mode['code'] = df_mode['code'].astype('int32')\n",
    "\n",
    "    return df_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-99</td>\n",
       "      <td>No Mode Value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code     definition\n",
       "0     1            Air\n",
       "1     2            Sea\n",
       "2     3           Land\n",
       "3     9   Not reported\n",
       "4   -99  No Mode Value"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode = extract_mode()\n",
    "df_mode.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Extracting Ports from Description File - SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_port():\n",
    "    \"\"\"\n",
    "    This function has no parameter \n",
    "    extracts port from sas file and return \n",
    "     \"\"\"\n",
    "    df_port = extract_content(\"$i94prtl\")\n",
    "    df_port.loc[len(df_port.index)] = ['-99', 'No Port Value']\n",
    "    df_port.insert(0,'id',range(1,1+len(df_port)))\n",
    "    return df_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE, AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW, AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id code                    definition\n",
       "0   1  ALC                     ALCAN, AK\n",
       "1   2  ANC                 ANCHORAGE, AK\n",
       "2   3  BAR  BAKER AAF - BAKER ISLAND, AK\n",
       "3   4  DAC             DALTONS CACHE, AK\n",
       "4   5  PIZ    DEW STATION PT LAY DEW, AK"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_port = extract_port()\n",
    "df_port.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Extracting Visa Types from Description File - SAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_visa():\n",
    "    \"\"\"\n",
    "    This function has no parameter \n",
    "    extracts visa from sas file and return \n",
    "    \"\"\"\n",
    "    df_visa = extract_content(\"I94VISA\")\n",
    "    df_visa.loc[len(df_visa.index)] = ['-99', 'No Visa Value']\n",
    "\n",
    "    return df_visa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-99</td>\n",
       "      <td>No Visa Value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code     definition\n",
       "0    1       Business\n",
       "1    2       Pleasure\n",
       "2    3        Student\n",
       "3  -99  No Visa Value"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visa = extract_visa()\n",
    "df_visa.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Combining parquet files to create main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def combining_parquet_files_i94():\n",
    "# I will in clude just 1 month for the request - if needed other months can be added and the code will collect and combine all of the data together\n",
    "    mounts = [\"jan\"]\n",
    "    fields = ['cicid','i94yr', 'i94cit', 'i94res', 'i94port', 'arrdate', 'i94mode', 'i94addr', \n",
    "                  'depdate', 'i94bir', 'entdepa', 'entdepd', 'entdepu', \n",
    "                  'biryear', 'dtaddto', 'gender', 'airline', 'visatype','i94visa']\n",
    "\n",
    "    for month in mounts:\n",
    "        fn = f'../../data/18-83510-I94-Data-2016/i94_{month}16_sub.sas7bdat'\n",
    "        # student visa only!\n",
    "        df_temp = spark.read.format('com.github.saurfang.sas.spark').load(fn)\n",
    "        df_temp = df_temp.select(fields)\n",
    "\n",
    "        if month == 'jan':\n",
    "            df_i94_final = df_temp\n",
    "        else:\n",
    "            df_i94_final = df_i94_final.union(df_temp)\n",
    "\n",
    "    return df_i94_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Count of i94 dataset :  2847924\n"
     ]
    }
   ],
   "source": [
    "df_i94_final = combining_parquet_files_i94()\n",
    "print('Total Count of i94 dataset : ',df_i94_final.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Checking & Cleaning Operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Datasets are loaded and ready to data checking and cleaning operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# i94 immigration data check and cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def i94_data_check_cleanse(df_i94):\n",
    "    print('starting data cleanse opearations of i94 dataset')\n",
    "    df_i94_final=df_i94\n",
    "    # Checking duplicated id's inside of df_i94_final\n",
    "    print(f\"Duplicated Cicid Values : {df_i94_final.groupby('cicid').count().filter(col('count')>1).count()}\")\n",
    "    \n",
    "    df_i94_final = df_i94_final.dropDuplicates(['cicid'])\n",
    "    print(f\"Duplicated Cicid Values : {df_i94_final.groupby('cicid').count().filter(col('count')>1).count()}\")\n",
    "    \n",
    "    # checking missing values of all columns of cicid cleaned dataset\n",
    "    print('checking missing values of all columns')\n",
    "    df_i94_final.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_i94_final.columns]).show()\n",
    "    \n",
    "    df_i94_final = df_i94_final.fillna({'i94cit':-99, 'i94mode':-99, 'i94addr':'-99', 'depdate':0, 'i94bir':0, 'entdepa':'', 'entdepd':'',\n",
    "                              'entdepu':'', 'biryear':0, 'dtaddto':'', 'gender':'', 'airline': '-99', 'i94visa':'-99'})\n",
    "    \n",
    "    df_i94_final.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_i94_final.columns]).show()\n",
    "    \n",
    "    #Renaming columns of i94_final datset\n",
    "    df_i94_final = df_i94_final.withColumnRenamed('cicid', 'id') \\\n",
    "        .withColumnRenamed('i94yr', 'year') \\\n",
    "        .withColumnRenamed('i94res', 'country') \\\n",
    "        .withColumnRenamed('i94port', 'port') \\\n",
    "        .withColumnRenamed('i94mode', 'mode') \\\n",
    "        .withColumnRenamed('i94addr', 'state') \\\n",
    "        .withColumnRenamed('i94bir', 'age') \\\n",
    "        .withColumnRenamed('gender', 'gender') \\\n",
    "        .withColumnRenamed('biryear', 'birth_year') \\\n",
    "        .withColumnRenamed('airline', 'air_line') \\\n",
    "        .withColumnRenamed('visatype', 'visa_type') \\\n",
    "        .withColumnRenamed('i94visa', 'visa') \\\n",
    "        .drop(\"i94cit\") \\\n",
    "        .drop(\"depdate\") \\\n",
    "        .drop(\"dtaddto\") \\\n",
    "        .drop(\"entdepa\") \\\n",
    "        .drop(\"entdepd\") \\\n",
    "        .drop(\"entdepu\") \\\n",
    "        .drop(\"arrdate\")\n",
    "    \n",
    "    df_i94_final.show(1)\n",
    "    \n",
    "    print('data check and cleanse operations completed for i94_datset')\n",
    "    return df_i94_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting data cleanse opearations of i94 dataset\n",
      "Duplicated Cicid Values : 0\n",
      "Duplicated Cicid Values : 0\n",
      "checking missing values of all columns\n",
      "+-----+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+------+-------+--------+-------+\n",
      "|cicid|i94yr|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|entdepa|entdepd|entdepu|biryear|dtaddto|gender|airline|visatype|i94visa|\n",
      "+-----+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+------+-------+--------+-------+\n",
      "|    0|    0|     0|     0|      0|      0|     60| 177129| 522612|  1190|     61| 521813|2847880|   1190|    707|216929|  61279|       0|      0|\n",
      "+-----+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+------+-------+--------+-------+\n",
      "\n",
      "+-----+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+------+-------+--------+-------+\n",
      "|cicid|i94yr|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|entdepa|entdepd|entdepu|biryear|dtaddto|gender|airline|visatype|i94visa|\n",
      "+-----+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+------+-------+--------+-------+\n",
      "|    0|    0|     0|     0|      0|      0|      0|      0|      0|     0|      0|      0|      0|      0|      0|     0|      0|       0|      0|\n",
      "+-----+-----+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+------+-------+--------+-------+\n",
      "\n",
      "+-----+------+-------+----+----+-----+----+----------+------+--------+---------+----+\n",
      "|   id|  year|country|port|mode|state| age|birth_year|gender|air_line|visa_type|visa|\n",
      "+-----+------+-------+----+----+-----+----+----------+------+--------+---------+----+\n",
      "|299.0|2016.0|  103.0| BOS| 1.0|   RI|25.0|    1991.0|     M|      LX|       F1| 3.0|\n",
      "+-----+------+-------+----+----+-----+----+----------+------+--------+---------+----+\n",
      "only showing top 1 row\n",
      "\n",
      "data check and cleanse operations completed for i94_datset\n"
     ]
    }
   ],
   "source": [
    "# calling function i94 data cleanse , data check and column rename for use\n",
    "df_i94_final = i94_data_check_cleanse(df_i94_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Demographics data check and cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def demographics_data_check_cleanse(df_demo):\n",
    "    subset_cols = [\n",
    "    'Male Population',\n",
    "    'Female Population',\n",
    "    'Number of Veterans',\n",
    "    'Foreign-born',\n",
    "    'Average Household Size'\n",
    "    ]\n",
    "    new_df_demo = df_demo.dropna(subset=subset_cols)\n",
    "\n",
    "    dropped = df_demo.count() - new_df_demo.count()\n",
    "    print(\"Dropped rows with missing values: {}\".format(dropped))\n",
    "\n",
    "    # dropping duplicate columns\n",
    "    df_demo_final = new_df_demo.dropDuplicates(subset=['City', 'State', 'State Code', 'Race'])\n",
    "\n",
    "    result  = new_df_demo.count() - df_demo_final.count()\n",
    "    print(f\"After dropping duplicates: {result}\")\n",
    "    \n",
    "    # Grouping data by state then we can connect with state key to our immigratin date\n",
    "    df_demo_final.createOrReplaceTempView(\"dm\")\n",
    "    sdf = spark.sql(\"SELECT dm.* FROM dm where dm.state ='Maryland'\")\n",
    "    sdf.show(3)\n",
    "    \n",
    "    # Rename and drop operations for demographic dataframe\n",
    "    print('Rename and drop columns')\n",
    "    df_demo_final = df_demo_final.drop('Median Age') \\\n",
    "        .withColumnRenamed('Male Population', 'male_population') \\\n",
    "        .withColumnRenamed('Female Population', 'female_population') \\\n",
    "        .withColumnRenamed('Total Population', 'total_population') \\\n",
    "        .withColumnRenamed('Number of Veterans', 'number_of_veterans') \\\n",
    "        .withColumnRenamed('Foreign-born', 'foreign_born') \\\n",
    "        .withColumnRenamed('Average Household Size', 'average_household_size') \\\n",
    "        .withColumnRenamed('State Code', 'state_code') \\\n",
    "        .drop(\"Race\") \\\n",
    "        .drop(\"City\")\n",
    "    df_demo_final.show(1)\n",
    "    \n",
    "    # Grouping all states and collecting all count data together for the spesific states and we can overview data by State\n",
    "    print('grouping data with using state_code')\n",
    "    df_demo_final = df_demo_final.groupby('state_code').agg({ 'male_population':'sum', \n",
    "                                                'female_population':'sum', \n",
    "                                                'total_population':'sum', \n",
    "                                                'number_of_veterans':'sum',\n",
    "                                                'foreign_born':'sum',\n",
    "                                                'average_household_size':'mean',\n",
    "                                               })\n",
    "    # Lets see what we did \n",
    "    df_demo_final.createOrReplaceTempView(\"dm\")\n",
    "    sdf = spark.sql(\"SELECT dm.* FROM dm where dm.state_code ='MD'\")\n",
    "    sdf.show(3)\n",
    "    \n",
    "    print('after aggrigating column names changed as sum avg titled , Cleaning these titles again')\n",
    "    df_demo_final = df_demo_final.drop('Median Age') \\\n",
    "        .withColumnRenamed('sum(male_population)', 'male_population') \\\n",
    "        .withColumnRenamed('sum(female_population)', 'female_population') \\\n",
    "        .withColumnRenamed('sum(total_population)', 'total_population') \\\n",
    "        .withColumnRenamed('sum(number_of_veterans)', 'number_of_veterans') \\\n",
    "        .withColumnRenamed('sum(foreign_born)', 'foreign_born') \\\n",
    "        .withColumnRenamed('avg(average_household_size)', 'average_household_size') \\\n",
    "        .withColumnRenamed('State Code', 'state_code') \n",
    "\n",
    "    df_demo_final.show(1)\n",
    "    \n",
    "    print('Demographic data cleansing and data operations are completed')                                           \n",
    "    \n",
    "    \n",
    "    return df_demo_final\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows with missing values: 16\n",
      "After dropping duplicates: 0\n",
      "+-------------+--------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|         City|   State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+-------------+--------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|       German|Maryland|      34.9|          41115|            43007|           84122|              2443|       27877|                  2.95|        MD|Black or African-...|22273|\n",
      "|Silver Spring|Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|               Asian| 8841|\n",
      "|     Columbia|Maryland|      37.9|          52202|            51265|          103467|              6526|       23249|                  2.68|        MD|               White|58343|\n",
      "+-------------+--------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "Rename and drop columns\n",
      "+-------------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+-----+\n",
      "|        State|male_population|female_population|total_population|number_of_veterans|foreign_born|average_household_size|state_code|Count|\n",
      "+-------------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+-----+\n",
      "|Massachusetts|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|58723|\n",
      "+-------------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+-----+\n",
      "only showing top 1 row\n",
      "\n",
      "grouping data with using state_code\n",
      "+----------+-----------------+--------------------+---------------------------+---------------------+----------------------+-----------------------+\n",
      "|state_code|sum(foreign_born)|sum(male_population)|avg(average_household_size)|sum(total_population)|sum(female_population)|sum(number_of_veterans)|\n",
      "+----------+-----------------+--------------------+---------------------------+---------------------+----------------------+-----------------------+\n",
      "|        MD|          1148970|             3139755|         2.6550000000000007|              6560645|               3420890|                 320715|\n",
      "+----------+-----------------+--------------------+---------------------------+---------------------+----------------------+-----------------------+\n",
      "\n",
      "after aggrigating column names changed as sum avg titled , Cleaning these titles again\n",
      "+----------+------------+---------------+----------------------+----------------+-----------------+------------------+\n",
      "|state_code|foreign_born|male_population|average_household_size|total_population|female_population|number_of_veterans|\n",
      "+----------+------------+---------------+----------------------+----------------+-----------------+------------------+\n",
      "|        AZ|     3411565|       11137275|    2.7743749999999996|        22497710|         11360435|           1322525|\n",
      "+----------+------------+---------------+----------------------+----------------+-----------------+------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "Demographic data cleansing and data operations are completed\n"
     ]
    }
   ],
   "source": [
    "# calling demo cleaning and data operation function\n",
    "df_demo_final = demographics_data_check_cleanse(df_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Country data check and cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def country_data_check_cleanse(country):\n",
    "    df_country=country\n",
    "    # in country data there are some dirty values and need to clean or group them  to make data more reliable\n",
    "    print('cleaning country dataset')\n",
    "    df_country.drop_duplicates(subset=[\"code\",\"definition\"],keep=False,inplace = True)\n",
    "    df_country.loc[df_country[\"definition\"].str.contains(\"INVALID*\"), \"definition\"] = \"Other\"\n",
    "    df_country.loc[df_country[\"definition\"].str.contains(\"No Country*\"), \"definition\"] = \"Other\"\n",
    "    df_country.loc[df_country[\"definition\"].str.contains(\"Collapsed*\"), \"definition\"] = \"Other\"\n",
    "    print('cleanse completed')\n",
    "    return df_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning country dataset\n",
      "cleanse completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>529</td>\n",
       "      <td>ANGUILLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>518</td>\n",
       "      <td>ANTIGUA-BARBUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>687</td>\n",
       "      <td>ARGENTINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151</td>\n",
       "      <td>ARMENIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>532</td>\n",
       "      <td>ARUBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>438</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>103</td>\n",
       "      <td>AUSTRIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>152</td>\n",
       "      <td>AZERBAIJAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>512</td>\n",
       "      <td>BAHAMAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>298</td>\n",
       "      <td>BAHRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>274</td>\n",
       "      <td>BANGLADESH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>513</td>\n",
       "      <td>BARBADOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>104</td>\n",
       "      <td>BELGIUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>581</td>\n",
       "      <td>BELIZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>386</td>\n",
       "      <td>BENIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>509</td>\n",
       "      <td>BERMUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>153</td>\n",
       "      <td>BELARUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>242</td>\n",
       "      <td>BHUTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>688</td>\n",
       "      <td>BOLIVIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>717</td>\n",
       "      <td>BONAIRE, ST EUSTATIUS, SABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>164</td>\n",
       "      <td>BOSNIA-HERZEGOVINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>336</td>\n",
       "      <td>BOTSWANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>689</td>\n",
       "      <td>BRAZIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>525</td>\n",
       "      <td>BRITISH VIRGIN ISLANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>239</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>134</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>506</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>755</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>311</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>741</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>54</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>100</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>187</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>190</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>200</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>219</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>238</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>277</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>293</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>300</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>319</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>365</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>395</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>400</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>485</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>503</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>589</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>592</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>791</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>849</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>914</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>944</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>996</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>99</td>\n",
       "      <td>All Other Codes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>290 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     code                                         definition\n",
       "0     582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1     236                                        AFGHANISTAN\n",
       "2     101                                            ALBANIA\n",
       "3     316                                            ALGERIA\n",
       "4     102                                            ANDORRA\n",
       "5     324                                             ANGOLA\n",
       "6     529                                           ANGUILLA\n",
       "7     518                                    ANTIGUA-BARBUDA\n",
       "8     687                                          ARGENTINA\n",
       "9     151                                            ARMENIA\n",
       "10    532                                              ARUBA\n",
       "11    438                                          AUSTRALIA\n",
       "12    103                                            AUSTRIA\n",
       "13    152                                         AZERBAIJAN\n",
       "14    512                                            BAHAMAS\n",
       "15    298                                            BAHRAIN\n",
       "16    274                                         BANGLADESH\n",
       "17    513                                           BARBADOS\n",
       "18    104                                            BELGIUM\n",
       "19    581                                             BELIZE\n",
       "20    386                                              BENIN\n",
       "21    509                                            BERMUDA\n",
       "22    153                                            BELARUS\n",
       "23    242                                             BHUTAN\n",
       "24    688                                            BOLIVIA\n",
       "25    717                        BONAIRE, ST EUSTATIUS, SABA\n",
       "26    164                                 BOSNIA-HERZEGOVINA\n",
       "27    336                                           BOTSWANA\n",
       "28    689                                             BRAZIL\n",
       "29    525                             BRITISH VIRGIN ISLANDS\n",
       "..    ...                                                ...\n",
       "260   239                                              Other\n",
       "261   134                                              Other\n",
       "262   506                                              Other\n",
       "263   755                                              Other\n",
       "264   311                                              Other\n",
       "265   741                                              Other\n",
       "266    54                                              Other\n",
       "267   100                                              Other\n",
       "268   187                                              Other\n",
       "269   190                                              Other\n",
       "270   200                                              Other\n",
       "271   219                                              Other\n",
       "272   238                                              Other\n",
       "273   277                                              Other\n",
       "274   293                                              Other\n",
       "275   300                                              Other\n",
       "276   319                                              Other\n",
       "277   365                                              Other\n",
       "278   395                                              Other\n",
       "279   400                                              Other\n",
       "280   485                                              Other\n",
       "281   503                                              Other\n",
       "282   589                                              Other\n",
       "283   592                                              Other\n",
       "284   791                                              Other\n",
       "285   849                                              Other\n",
       "286   914                                              Other\n",
       "287   944                                              Other\n",
       "288   996                                              Other\n",
       "289    99                                    All Other Codes\n",
       "\n",
       "[290 rows x 2 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_data_check_cleanse(df_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Port data check and cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def port_data_check_cleanse(port):\n",
    "    df_port=port\n",
    "    df_port.drop_duplicates(subset=[\"code\",\"definition\"],keep=False,inplace = True)\n",
    "    df_port.loc[df_port[\"definition\"].str.contains(\"INVALID*\"), \"definition\"] = \"Other\"\n",
    "    df_port.loc[df_port[\"definition\"].str.contains(\"No Port*\"), \"definition\"] = \"Other\"\n",
    "    df_port.loc[df_port[\"definition\"].str.contains(\"Collapsed*\"), \"definition\"] = \"Other\"\n",
    "    return port\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-99</td>\n",
       "      <td>No Mode Value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code     definition\n",
       "0     1            Air\n",
       "1     2            Sea\n",
       "2     3           Land\n",
       "3     9   Not reported\n",
       "4   -99  No Mode Value"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_data_check_cleanse(df_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Visa data check and cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def visa_data_check_cleanse(visa):\n",
    "    df_visa=visa\n",
    "    df_visa.drop_duplicates(subset=[\"code\",\"definition\"],keep=False,inplace = True)\n",
    "    print('dropping duplicates of visa dataset')\n",
    "    return df_visa\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping duplicates of visa dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-99</td>\n",
       "      <td>No Visa Value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code     definition\n",
       "0    1       Business\n",
       "1    2       Pleasure\n",
       "2    3        Student\n",
       "3  -99  No Visa Value"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visa_data_check_cleanse(df_visa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Mode data check and cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def mode_data_check_cleanse(mode):\n",
    "    df_mode = mode\n",
    "    df_mode.drop_duplicates(subset=[\"code\",\"definition\"],keep=False,inplace = True)\n",
    "    print('dropping duplicates of mode dataset - mode')\n",
    "    return df_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping duplicates of mode dataset - mode\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-99</td>\n",
       "      <td>No Mode Value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code     definition\n",
       "0     1            Air\n",
       "1     2            Sea\n",
       "2     3           Land\n",
       "3     9   Not reported\n",
       "4   -99  No Mode Value"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_data_check_cleanse(df_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### State data check and cleaning operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def state_data_check_cleanse(state):\n",
    "    df_state=state\n",
    "    df_state.drop_duplicates(subset=[\"code\",\"definition\"],keep=False,inplace = True)\n",
    "    df_state.loc[df_state[\"definition\"].str.contains(\"INVALID*\"), \"definition\"] = \"Other\"\n",
    "    df_state.loc[df_state[\"definition\"].str.contains(\"No Port*\"), \"definition\"] = \"Other\"\n",
    "    df_state.loc[df_state[\"definition\"].str.contains(\"Collapsed*\"), \"definition\"] = \"Other\"\n",
    "    print('dropped duplicates and cleanse columns - state')\n",
    "    return df_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped duplicates and cleanse columns - state\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>CO</td>\n",
       "      <td>COLORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>CT</td>\n",
       "      <td>CONNECTICUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>DE</td>\n",
       "      <td>DELAWARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>DC</td>\n",
       "      <td>DIST. OF COLUMBIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>FL</td>\n",
       "      <td>FLORIDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>GA</td>\n",
       "      <td>GEORGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>GU</td>\n",
       "      <td>GUAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>HI</td>\n",
       "      <td>HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>ID</td>\n",
       "      <td>IDAHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>IL</td>\n",
       "      <td>ILLINOIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>IN</td>\n",
       "      <td>INDIANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>IA</td>\n",
       "      <td>IOWA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>KS</td>\n",
       "      <td>KANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>KY</td>\n",
       "      <td>KENTUCKY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>LA</td>\n",
       "      <td>LOUISIANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>ME</td>\n",
       "      <td>MAINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>MD</td>\n",
       "      <td>MARYLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>MA</td>\n",
       "      <td>MASSACHUSETTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>MI</td>\n",
       "      <td>MICHIGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>MN</td>\n",
       "      <td>MINNESOTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>MS</td>\n",
       "      <td>MISSISSIPPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>MO</td>\n",
       "      <td>MISSOURI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>MT</td>\n",
       "      <td>MONTANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>NC</td>\n",
       "      <td>N. CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>ND</td>\n",
       "      <td>N. DAKOTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>NE</td>\n",
       "      <td>NEBRASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>NV</td>\n",
       "      <td>NEVADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>NH</td>\n",
       "      <td>NEW HAMPSHIRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NEW JERSEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>NM</td>\n",
       "      <td>NEW MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>NY</td>\n",
       "      <td>NEW YORK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>OH</td>\n",
       "      <td>OHIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>OK</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>OR</td>\n",
       "      <td>OREGON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>PA</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>PR</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>RI</td>\n",
       "      <td>RHODE ISLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>SC</td>\n",
       "      <td>S. CAROLINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>SD</td>\n",
       "      <td>S. DAKOTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>TN</td>\n",
       "      <td>TENNESSEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>TX</td>\n",
       "      <td>TEXAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>UT</td>\n",
       "      <td>UTAH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>VT</td>\n",
       "      <td>VERMONT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>VI</td>\n",
       "      <td>VIRGIN ISLANDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>VA</td>\n",
       "      <td>VIRGINIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>WV</td>\n",
       "      <td>W. VIRGINIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>WA</td>\n",
       "      <td>WASHINGTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>WI</td>\n",
       "      <td>WISCONSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>WY</td>\n",
       "      <td>WYOMING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>99</td>\n",
       "      <td>All Other Codes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id code         definition\n",
       "0    1   AL            ALABAMA\n",
       "1    2   AK             ALASKA\n",
       "2    3   AZ            ARIZONA\n",
       "3    4   AR           ARKANSAS\n",
       "4    5   CA         CALIFORNIA\n",
       "5    6   CO           COLORADO\n",
       "6    7   CT        CONNECTICUT\n",
       "7    8   DE           DELAWARE\n",
       "8    9   DC  DIST. OF COLUMBIA\n",
       "9   10   FL            FLORIDA\n",
       "10  11   GA            GEORGIA\n",
       "11  12   GU               GUAM\n",
       "12  13   HI             HAWAII\n",
       "13  14   ID              IDAHO\n",
       "14  15   IL           ILLINOIS\n",
       "15  16   IN            INDIANA\n",
       "16  17   IA               IOWA\n",
       "17  18   KS             KANSAS\n",
       "18  19   KY           KENTUCKY\n",
       "19  20   LA          LOUISIANA\n",
       "20  21   ME              MAINE\n",
       "21  22   MD           MARYLAND\n",
       "22  23   MA      MASSACHUSETTS\n",
       "23  24   MI           MICHIGAN\n",
       "24  25   MN          MINNESOTA\n",
       "25  26   MS        MISSISSIPPI\n",
       "26  27   MO           MISSOURI\n",
       "27  28   MT            MONTANA\n",
       "28  29   NC        N. CAROLINA\n",
       "29  30   ND          N. DAKOTA\n",
       "30  31   NE           NEBRASKA\n",
       "31  32   NV             NEVADA\n",
       "32  33   NH      NEW HAMPSHIRE\n",
       "33  34   NJ         NEW JERSEY\n",
       "34  35   NM         NEW MEXICO\n",
       "35  36   NY           NEW YORK\n",
       "36  37   OH               OHIO\n",
       "37  38   OK           OKLAHOMA\n",
       "38  39   OR             OREGON\n",
       "39  40   PA       PENNSYLVANIA\n",
       "40  41   PR        PUERTO RICO\n",
       "41  42   RI       RHODE ISLAND\n",
       "42  43   SC        S. CAROLINA\n",
       "43  44   SD          S. DAKOTA\n",
       "44  45   TN          TENNESSEE\n",
       "45  46   TX              TEXAS\n",
       "46  47   UT               UTAH\n",
       "47  48   VT            VERMONT\n",
       "48  49   VI     VIRGIN ISLANDS\n",
       "49  50   VA           VIRGINIA\n",
       "50  51   WV        W. VIRGINIA\n",
       "51  52   WA         WASHINGTON\n",
       "52  53   WI          WISCONSON\n",
       "53  54   WY            WYOMING\n",
       "54  55   99    All Other Codes"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_data_check_cleanse(df_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "toggleable": false,
    "ulab": {
     "buttons": {
      "ulab-button-toggle-a43bfc84": {
       "style": "primary"
      }
     }
    }
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Conceptual data model that I designed containes i94 usa immigration data as fact table and directly relations with demographics , port , visa , state , country and mode which are designed as dimension tables.<br>\n",
    "\n",
    "These are just files but I transform them easy to implement as star Schema because of project concept and needs. Questions create queries focuses on immigration data and I want to replied as fast as we can even data size will be increase in time but based on data architecture we can still able to serve reliable performance.\n",
    "\n",
    "![title](images/Final_Data_Model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "* Loading datasets\n",
    "* Extracting visa , port , mode , state and country datasets\n",
    "* Cleaning all datasets\n",
    "* Creating dims and fact table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def converting_state_to_spark(state):\n",
    "    df_state=state\n",
    "    # Creating Schema and converting columns    -  STATE\n",
    "    state_schema = StructType([StructField(\"id\",IntegerType(),True)\n",
    "                              ,StructField(\"code\",StringType(),True) \\\n",
    "                              ,StructField(\"definition\",StringType(),True)])\n",
    "\n",
    "    state_spark_df = spark.createDataFrame(df_state,schema=state_schema)\n",
    "    state_spark_df.printSchema()\n",
    "    state_spark_df.show()\n",
    "    return state_spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- definition: string (nullable = true)\n",
      "\n",
      "+---+----+-----------------+\n",
      "| id|code|       definition|\n",
      "+---+----+-----------------+\n",
      "|  1|  AL|          ALABAMA|\n",
      "|  2|  AK|           ALASKA|\n",
      "|  3|  AZ|          ARIZONA|\n",
      "|  4|  AR|         ARKANSAS|\n",
      "|  5|  CA|       CALIFORNIA|\n",
      "|  6|  CO|         COLORADO|\n",
      "|  7|  CT|      CONNECTICUT|\n",
      "|  8|  DE|         DELAWARE|\n",
      "|  9|  DC|DIST. OF COLUMBIA|\n",
      "| 10|  FL|          FLORIDA|\n",
      "| 11|  GA|          GEORGIA|\n",
      "| 12|  GU|             GUAM|\n",
      "| 13|  HI|           HAWAII|\n",
      "| 14|  ID|            IDAHO|\n",
      "| 15|  IL|         ILLINOIS|\n",
      "| 16|  IN|          INDIANA|\n",
      "| 17|  IA|             IOWA|\n",
      "| 18|  KS|           KANSAS|\n",
      "| 19|  KY|         KENTUCKY|\n",
      "| 20|  LA|        LOUISIANA|\n",
      "+---+----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_spark_df=converting_state_to_spark(df_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def converting_country_to_spark(country):\n",
    "    df_country = country\n",
    "    # Creating Schema and converting columns    -  Country\n",
    "    country_schema = StructType([StructField(\"code\",StringType(),True) \\\n",
    "                              ,StructField(\"definition\",StringType(),True)])\n",
    "\n",
    "    country_spark_df = spark.createDataFrame(df_country,schema=country_schema)\n",
    "    country_spark_df.printSchema()\n",
    "    country_spark_df.show()\n",
    "    return country_spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- definition: string (nullable = true)\n",
      "\n",
      "+----+--------------------+\n",
      "|code|          definition|\n",
      "+----+--------------------+\n",
      "| 582|MEXICO Air Sea, a...|\n",
      "| 236|         AFGHANISTAN|\n",
      "| 101|             ALBANIA|\n",
      "| 316|             ALGERIA|\n",
      "| 102|             ANDORRA|\n",
      "| 324|              ANGOLA|\n",
      "| 529|            ANGUILLA|\n",
      "| 518|     ANTIGUA-BARBUDA|\n",
      "| 687|           ARGENTINA|\n",
      "| 151|             ARMENIA|\n",
      "| 532|               ARUBA|\n",
      "| 438|           AUSTRALIA|\n",
      "| 103|             AUSTRIA|\n",
      "| 152|          AZERBAIJAN|\n",
      "| 512|             BAHAMAS|\n",
      "| 298|             BAHRAIN|\n",
      "| 274|          BANGLADESH|\n",
      "| 513|            BARBADOS|\n",
      "| 104|             BELGIUM|\n",
      "| 581|              BELIZE|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_spark_df=converting_country_to_spark(df_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def converting_mode_to_spark(mode):\n",
    "    df_mode=mode\n",
    "    # Creating Schema and converting columns    -  Mode\n",
    "    mode_schema = StructType([StructField(\"code\",StringType(),True) \\\n",
    "                              ,StructField(\"definition\",StringType(),True)])\n",
    "\n",
    "    mode_spark_df = spark.createDataFrame(df_mode,schema=mode_schema)\n",
    "    mode_spark_df.printSchema()\n",
    "    mode_spark_df.show()\n",
    "    return mode_spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- definition: string (nullable = true)\n",
      "\n",
      "+----+-------------+\n",
      "|code|   definition|\n",
      "+----+-------------+\n",
      "|   1|          Air|\n",
      "|   2|          Sea|\n",
      "|   3|         Land|\n",
      "|   9| Not reported|\n",
      "| -99|No Mode Value|\n",
      "+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mode_spark_df=converting_mode_to_spark(df_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def converting_visa_to_spark(visa):\n",
    "    df_visa=visa\n",
    "    # Creating Schema and converting columns    -  Visa\n",
    "    visa_schema = StructType([StructField(\"code\",StringType(),True) \\\n",
    "                              ,StructField(\"definition\",StringType(),True)])\n",
    "\n",
    "    visa_spark_df = spark.createDataFrame(df_visa,schema=visa_schema)\n",
    "    visa_spark_df.printSchema()\n",
    "    visa_spark_df.show()\n",
    "    return visa_spark_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- definition: string (nullable = true)\n",
      "\n",
      "+----+-------------+\n",
      "|code|   definition|\n",
      "+----+-------------+\n",
      "|   1|     Business|\n",
      "|   2|     Pleasure|\n",
      "|   3|      Student|\n",
      "| -99|No Visa Value|\n",
      "+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visa_spark_df=converting_visa_to_spark(df_visa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def converting_port_to_spark(port):\n",
    "    df_port=port\n",
    "    # Creating Schema and converting columns    -  Port\n",
    "    port_schema = StructType([StructField(\"id\",IntegerType(),True)\\\n",
    "                              ,StructField(\"code\",StringType(),True) \\\n",
    "                              ,StructField(\"definition\",StringType(),True)])\n",
    "\n",
    "    port_spark_df = spark.createDataFrame(df_port,schema=port_schema)\n",
    "    port_spark_df.printSchema()\n",
    "    port_spark_df.show()\n",
    "    return port_spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- definition: string (nullable = true)\n",
      "\n",
      "+---+----+--------------------+\n",
      "| id|code|          definition|\n",
      "+---+----+--------------------+\n",
      "|  1| ALC|           ALCAN, AK|\n",
      "|  2| ANC|       ANCHORAGE, AK|\n",
      "|  3| BAR|BAKER AAF - BAKER...|\n",
      "|  4| DAC|   DALTONS CACHE, AK|\n",
      "|  5| PIZ|DEW STATION PT LA...|\n",
      "|  6| DTH|    DUTCH HARBOR, AK|\n",
      "|  7| EGL|           EAGLE, AK|\n",
      "|  8| FRB|       FAIRBANKS, AK|\n",
      "|  9| HOM|           HOMER, AK|\n",
      "| 10| HYD|           HYDER, AK|\n",
      "| 11| JUN|          JUNEAU, AK|\n",
      "| 12| 5KE|       KETCHIKAN, AK|\n",
      "| 13| KET|       KETCHIKAN, AK|\n",
      "| 14| MOS|MOSES POINT INTER...|\n",
      "| 15| NIK|         NIKISKI, AK|\n",
      "| 16| NOM|             NOM, AK|\n",
      "| 17| PKC|     POKER CREEK, AK|\n",
      "| 18| ORI|  PORT LIONS SPB, AK|\n",
      "| 19| SKA|         SKAGWAY, AK|\n",
      "| 20| SNP| ST. PAUL ISLAND, AK|\n",
      "+---+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "port_spark_df=converting_port_to_spark(df_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: double (nullable = true)\n",
      " |-- year: double (nullable = true)\n",
      " |-- country: double (nullable = true)\n",
      " |-- port: string (nullable = true)\n",
      " |-- mode: double (nullable = false)\n",
      " |-- state: string (nullable = false)\n",
      " |-- age: double (nullable = false)\n",
      " |-- birth_year: double (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- air_line: string (nullable = false)\n",
      " |-- visa_type: string (nullable = true)\n",
      " |-- visa: double (nullable = true)\n",
      "\n",
      "+------+------+-------+----+----+-----+----+----------+------+--------+---------+----+\n",
      "|    id|  year|country|port|mode|state| age|birth_year|gender|air_line|visa_type|visa|\n",
      "+------+------+-------+----+----+-----+----+----------+------+--------+---------+----+\n",
      "| 299.0|2016.0|  103.0| BOS| 1.0|   RI|25.0|    1991.0|     M|      LX|       F1| 3.0|\n",
      "| 305.0|2016.0|  103.0| FTL| 1.0|   FL|24.0|    1992.0|     M|      BW|       F1| 3.0|\n",
      "| 558.0|2016.0|  104.0| PHI| 1.0|   CA|22.0|    1994.0|     F|      BA|       WT| 2.0|\n",
      "| 596.0|2016.0|  104.0| SEA| 1.0|   OR|49.0|    1967.0|     M|      DL|       WB| 1.0|\n",
      "| 692.0|2016.0|  104.0| NEW| 1.0|   NY|19.0|    1997.0|     M|      UA|       F1| 3.0|\n",
      "|1051.0|2016.0|  107.0| ATL| 1.0|   FL|58.0|    1958.0|     M|      KL|       B1| 1.0|\n",
      "|1761.0|2016.0|  107.0| SPM| 1.0|   MN|21.0|    1995.0|     F|      DL|       F1| 3.0|\n",
      "|3901.0|2016.0|  111.0| NYC| 1.0|   NY|39.0|    1977.0|     F|      AF|       WT| 2.0|\n",
      "|3980.0|2016.0|  111.0| PHI| 1.0|   FL|22.0|    1994.0|     F|      AA|       WT| 2.0|\n",
      "|4066.0|2016.0|  111.0| SFR| 1.0|   CA|48.0|    1968.0|     F|      AF|       WT| 2.0|\n",
      "+------+------+-------+----+----+-----+----+----------+------+--------+---------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating Schema and converting columns    -  i94 Immigration \n",
    "\n",
    "df_i94_final.printSchema()\n",
    "df_i94_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- foreign_born: long (nullable = true)\n",
      " |-- male_population: long (nullable = true)\n",
      " |-- average_household_size: double (nullable = true)\n",
      " |-- total_population: long (nullable = true)\n",
      " |-- female_population: long (nullable = true)\n",
      " |-- number_of_veterans: long (nullable = true)\n",
      "\n",
      "+----------+------------+---------------+----------------------+----------------+-----------------+------------------+\n",
      "|state_code|foreign_born|male_population|average_household_size|total_population|female_population|number_of_veterans|\n",
      "+----------+------------+---------------+----------------------+----------------+-----------------+------------------+\n",
      "|        AZ|     3411565|       11137275|    2.7743749999999996|        22497710|         11360435|           1322525|\n",
      "|        SC|      134019|        1265291|     2.469583333333333|         2586976|          1321685|            163334|\n",
      "|        LA|      417095|        3134990|                 2.465|         6502975|          3367985|            348855|\n",
      "|        MN|     1069888|        3478803|     2.496851851851851|         7044165|          3565362|            321738|\n",
      "|        NJ|     2327750|        3423033|    2.9608771929824558|         6931024|          3507991|            146632|\n",
      "|        DC|      475585|        1598525|                  2.24|         3361140|          1762615|            129815|\n",
      "|        OR|      928765|        3537215|    2.5387500000000007|         7182545|          3645330|            394740|\n",
      "|        VA|     1346270|        5802370|     2.584285714285714|        11818110|          6015740|           1148830|\n",
      "|        RI|      431507|         974791|     2.528947368421053|         1986112|          1011321|             87236|\n",
      "|        KY|      332440|        2262415|    2.3949999999999996|         4649385|          2386970|            280125|\n",
      "+----------+------------+---------------+----------------------+----------------+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_demo_final.printSchema()\n",
    "df_demo_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#  exporting files into parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def exporting_final_parquet_files():\n",
    "    #Export the demographics table.\n",
    "    print('Writing Demographic parquet files to /data_output/demographics_data')\n",
    "    df_demo_final.write.mode(\"overwrite\").parquet(\"./data_output/demographics_data\")\n",
    "    print('Demographic data writing completed')\n",
    "    \n",
    "    print('Writing i94 parquet files to /data_output/i94_data')\n",
    "    df_i94_final.write.mode(\"overwrite\").parquet(\"./data_output/i94_data\")\n",
    "    print('i94 data writing completed')\n",
    "    \n",
    "    print('Writing Port parquet files to /data_output/port_data')\n",
    "    port_spark_df.write.mode(\"overwrite\").parquet(\"./data_output/port_data\")\n",
    "    print('Port data writing completed')\n",
    "    \n",
    "    print('Writing Visa parquet files to /data_output/visa_data')\n",
    "    visa_spark_df.write.mode(\"overwrite\").parquet(\"./data_output/visa_data\")\n",
    "    print('Visa data writing completed')\n",
    "    \n",
    "    print('Writing State parquet files to /data_output/state_data')\n",
    "    state_spark_df.write.mode(\"overwrite\").parquet(\"./data_output/state_data\")\n",
    "    print('State data writing completed')\n",
    "    \n",
    "    print('Writing Country parquet files to /data_output/country_data')\n",
    "    country_spark_df.write.mode(\"overwrite\").parquet(\"./data_output/country_data\")\n",
    "    print('Country data writing completed')\n",
    "    \n",
    "    print('Writing Mode parquet files to /data_output/mode_data')\n",
    "    mode_spark_df.write.mode(\"overwrite\").parquet(\"./data_output/mode_data\")\n",
    "    print('Mode data writing completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Demographic parquet files to /data_output/demographics_data\n",
      "Demographic data writing completed\n",
      "Writing i94 parquet files to /data_output/i94_data\n",
      "i94 data writing completed\n",
      "Writing Port parquet files to /data_output/port_data\n",
      "Port data writing completed\n",
      "Writing Visa parquet files to /data_output/visa_data\n",
      "Visa data writing completed\n",
      "Writing State parquet files to /data_output/state_data\n",
      "State data writing completed\n",
      "Writing Country parquet files to /data_output/country_data\n",
      "Country data writing completed\n",
      "Writing Mode parquet files to /data_output/mode_data\n",
      "Mode data writing completed\n"
     ]
    }
   ],
   "source": [
    "# calling function that export all datasets into parquet files inside ./data/ with sub folders\n",
    "exporting_final_parquet_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-------+----+----+-----+----+----------+------+--------+---------+----+\n",
      "|id    |year  |country|port|mode|state|age |birth_year|gender|air_line|visa_type|visa|\n",
      "+------+------+-------+----+----+-----+----+----------+------+--------+---------+----+\n",
      "|299.0 |2016.0|103.0  |BOS |1.0 |RI   |25.0|1991.0    |M     |LX      |F1       |3.0 |\n",
      "|305.0 |2016.0|103.0  |FTL |1.0 |FL   |24.0|1992.0    |M     |BW      |F1       |3.0 |\n",
      "|558.0 |2016.0|104.0  |PHI |1.0 |CA   |22.0|1994.0    |F     |BA      |WT       |2.0 |\n",
      "|596.0 |2016.0|104.0  |SEA |1.0 |OR   |49.0|1967.0    |M     |DL      |WB       |1.0 |\n",
      "|692.0 |2016.0|104.0  |NEW |1.0 |NY   |19.0|1997.0    |M     |UA      |F1       |3.0 |\n",
      "|1051.0|2016.0|107.0  |ATL |1.0 |FL   |58.0|1958.0    |M     |KL      |B1       |1.0 |\n",
      "|1761.0|2016.0|107.0  |SPM |1.0 |MN   |21.0|1995.0    |F     |DL      |F1       |3.0 |\n",
      "|3901.0|2016.0|111.0  |NYC |1.0 |NY   |39.0|1977.0    |F     |AF      |WT       |2.0 |\n",
      "|3980.0|2016.0|111.0  |PHI |1.0 |FL   |22.0|1994.0    |F     |AA      |WT       |2.0 |\n",
      "|4066.0|2016.0|111.0  |SFR |1.0 |CA   |48.0|1968.0    |F     |AF      |WT       |2.0 |\n",
      "+------+------+-------+----+----+-----+----+----------+------+--------+---------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2847924"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last clean product like below , and getting all tables count \n",
    "df_i94_final.show(10,truncate=False)\n",
    "df_i94_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------------+----------------------+----------------+-----------------+------------------+\n",
      "|state_code|foreign_born|male_population|average_household_size|total_population|female_population|number_of_veterans|\n",
      "+----------+------------+---------------+----------------------+----------------+-----------------+------------------+\n",
      "|AZ        |3411565     |11137275       |2.7743749999999996    |22497710        |11360435         |1322525           |\n",
      "|SC        |134019      |1265291        |2.469583333333333     |2586976         |1321685          |163334            |\n",
      "|LA        |417095      |3134990        |2.465                 |6502975         |3367985          |348855            |\n",
      "|MN        |1069888     |3478803        |2.496851851851851     |7044165         |3565362          |321738            |\n",
      "|NJ        |2327750     |3423033        |2.9608771929824558    |6931024         |3507991          |146632            |\n",
      "|DC        |475585      |1598525        |2.24                  |3361140         |1762615          |129815            |\n",
      "|OR        |928765      |3537215        |2.5387500000000007    |7182545         |3645330          |394740            |\n",
      "|VA        |1346270     |5802370        |2.584285714285714     |11818110        |6015740          |1148830           |\n",
      "|RI        |431507      |974791         |2.528947368421053     |1986112         |1011321          |87236             |\n",
      "|KY        |332440      |2262415        |2.3949999999999996    |4649385         |2386970          |280125            |\n",
      "+----------+------------+---------------+----------------------+----------------+-----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo_final.show(10,truncate=False)\n",
    "df_demo_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------------------------+\n",
      "|id |code|definition                  |\n",
      "+---+----+----------------------------+\n",
      "|1  |ALC |ALCAN, AK                   |\n",
      "|2  |ANC |ANCHORAGE, AK               |\n",
      "|3  |BAR |BAKER AAF - BAKER ISLAND, AK|\n",
      "|4  |DAC |DALTONS CACHE, AK           |\n",
      "|5  |PIZ |DEW STATION PT LAY DEW, AK  |\n",
      "+---+----+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "661"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_spark_df.show(5,truncate=False)\n",
    "port_spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "|code|definition   |\n",
      "+----+-------------+\n",
      "|1   |Business     |\n",
      "|2   |Pleasure     |\n",
      "|3   |Student      |\n",
      "|-99 |No Visa Value|\n",
      "+----+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visa_spark_df.show(5,truncate=False)\n",
    "visa_spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----------+\n",
      "|id |code|definition|\n",
      "+---+----+----------+\n",
      "|1  |AL  |ALABAMA   |\n",
      "|2  |AK  |ALASKA    |\n",
      "|3  |AZ  |ARIZONA   |\n",
      "|4  |AR  |ARKANSAS  |\n",
      "|5  |CA  |CALIFORNIA|\n",
      "+---+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_spark_df.show(5,truncate=False)\n",
    "state_spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------------------------------------+\n",
      "|code|definition                                               |\n",
      "+----+---------------------------------------------------------+\n",
      "|582 |MEXICO Air Sea, and Not Reported (I-94, no land arrivals)|\n",
      "|236 |AFGHANISTAN                                              |\n",
      "|101 |ALBANIA                                                  |\n",
      "|316 |ALGERIA                                                  |\n",
      "|102 |ANDORRA                                                  |\n",
      "+----+---------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_spark_df.show(5,truncate=False)\n",
    "country_spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "|code|definition   |\n",
      "+----+-------------+\n",
      "|1   |Air          |\n",
      "|2   |Sea          |\n",
      "|3   |Land         |\n",
      "|9   |Not reported |\n",
      "|-99 |No Mode Value|\n",
      "+----+-------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_spark_df.show(5,truncate=False)\n",
    "mode_spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# df_i94_final\n",
    "\n",
    "Column | Description \n",
    "-----|-----\n",
    "id|record id for each column \n",
    "year| 4 digit of year \n",
    "country | immigrants residence country\n",
    "port| port information \n",
    "mode| which way to immigrant come to usa by air , sea ,land or not reported \n",
    "state| state that immigrant come to usa\n",
    "age| age \n",
    "birth_year| year of birth\n",
    "gender| gender of immigrant\n",
    "air_line| which airline while coming to usa\n",
    "visa_type| visa type for immigrant \n",
    "visa|visa (business , student , pleasure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# df_demo_final\n",
    "\n",
    "|state_code|foreign_born|male_population|average_household_size|total_population|female_population|number_of_veterans|\n",
    "\n",
    "Column | Description \n",
    "-----|-----\n",
    "state_code|state code\n",
    "foreign_born| total count of foreign born in that state\n",
    "male_population|total count of foreign male population in that state\n",
    "average_household_size|Average of household size in that state\n",
    "total_population|total count of population in that state\n",
    "female_population|total count of  female popuplation in that state\n",
    "number_of_veterans|total count of veterans in that state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# mode_spark_df\n",
    "Column | Description \n",
    "-----|-----\n",
    "code|mode code \n",
    "definition| definition stands for mode , how immigrant come to usa by air , land or sea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# country_spark_df\n",
    "Column | Description \n",
    "-----|-----\n",
    "code| country code\n",
    "definition| country name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# state_spark_df\n",
    "Column | Description \n",
    "-----|-----\n",
    "id|record id \n",
    "code|code of state\n",
    "definition| name of state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# visa_spark_df\n",
    "\n",
    "Column | Description \n",
    "-----|-----\n",
    "code|record if\n",
    "definition| visa definition student ,business or pleasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# port_spark_df\n",
    "Column | Description \n",
    "-----|-----\n",
    "id|record id \n",
    "code|code of port\n",
    "definition| name of port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "In this capstone project I mostly prefer to use apache spark and python pandas depending size on data. I like to use apache spark because of high read and transformation speed it's really easy to explore , clean and transform data with using Spark SQL is giving good advantage of time  and flexibility. After creating temporary views it's like normal sql operations but with high speed and big volume on data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Propose how often the data should be updated and why.\n",
    "The i94 immigration data should be updated once every 2 month and Demographic data should be updated every 6 month. We can monitor data increase size and compare them with every update after that we may update more often or later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The data was increased by 100x.\n",
    "Increased data size means we need more power of processing , storage and more complex solutions. I would prefer Amazon redshift clusters with increased node capacity depending on my workload and I would continue with using spark for my operations I will start to use EMR to able to store these kind of big data I go with HDFS too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "My first prefence will be definetly Apache Airflow but there are some other products exists too. I will implement elt steps by creating DAGs. like we did in airflow project I can create dags which can be run at 7 am  with daily scheduled and notifications can be added aswell by configurating our dag we can do that too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### The database needed to be accessed by 100+ people\n",
    "I understand that this data is valuable for more people and we should serve our data product with using data warehouse and business intelligence tools. I prefer to use postgres with using amazon redshift and personally I prefer oracle business intelligence or power bi for the analytic reporting tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
